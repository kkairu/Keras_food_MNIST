{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Keras-food_MNIST.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kkairu/Keras_food_MNIST/blob/master/Keras_food_MNIST.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xwFoRPFe7oZy",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "# food MNIST\n",
        "\n",
        "\n",
        "<img src=https://raw.githubusercontent.com/srohit0/food_mnist/master/images/food-collage.jpg  width=\"800\" height=\"400\" align=\"center\">"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qk8tUuH35FHl",
        "colab_type": "code",
        "outputId": "5e2e2bc0-9739-4614-b2bf-673c32887eda",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "%%time\n",
        "\n",
        "#! rm -fr food_mnist\n",
        "! git clone https://github.com/srohit0/food_mnist.git\n",
        "\n",
        "import food_mnist\n",
        "from google.colab.patches import cv2_imshow"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'food_mnist' already exists and is not an empty directory.\n",
            "CPU times: user 39.3 ms, sys: 19.3 ms, total: 58.7 ms\n",
            "Wall time: 847 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UrC_0vDFI_yj",
        "colab_type": "text"
      },
      "source": [
        "## 1. Import Packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HvlTMPFe41Uz",
        "colab_type": "code",
        "outputId": "93816354-71e1-45f1-e1a7-68804edaa4f9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "import tensorflow.keras\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import Dense, Dropout, Flatten,Input\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
        "from tensorflow.keras import backend as K\n",
        "from keras import regularizers\n",
        "\n",
        "np.random.seed(0) \n",
        "tf.set_random_seed(2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PqnAmuXC7t6s",
        "colab_type": "text"
      },
      "source": [
        "## 2. Load MNIST Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M1-Ot1Nh7li6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def randomize(dataset, labels):\n",
        "  permutation = np.random.permutation(labels.shape[0])\n",
        "  shuffled_dataset = dataset[permutation,:,:]\n",
        "  shuffled_labels = labels[permutation]\n",
        "  return shuffled_dataset, shuffled_labels\n",
        "\n",
        "\n",
        "\n",
        "def divide_dataset(dataset, labels):\n",
        "    train_pct = 0.80; \n",
        "    # divide dataset into training and validation set\n",
        "    train_index = int(dataset.shape[0]*train_pct)\n",
        "    t_X = dataset[:train_index, :]\n",
        "    t_Y = labels[:train_index]\n",
        "    v_X = dataset[train_index:,:]\n",
        "    v_Y = labels[train_index:]\n",
        "    \n",
        "    return (t_X, t_Y), (v_X, v_Y)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "89aWel8uCCtI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 1000\n",
        "num_classes = 10\n",
        "epochs = 100\n",
        "\n",
        "# input image dimensions\n",
        "img_rows, img_cols, img_channels = 56, 56, 3\n",
        "input_shape = (img_rows, img_cols, img_channels)\n",
        "\n",
        "# the data, split between train and test sets\n",
        "(x_train, y_train), (x_test, y_test) = food_mnist.load_data(img_cols, img_rows)\n",
        "X = np.concatenate((x_train, x_test), axis=0)\n",
        "Y = np.concatenate((y_train, y_test), axis=0)\n",
        "\n",
        "X, Y = randomize(X, Y)\n",
        "(x_train, y_train), (x_test, y_test) = divide_dataset(X, Y)\n",
        "\n",
        "x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, img_channels)\n",
        "x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, img_channels)\n",
        "\n",
        "x_train = x_train.astype('float16') / 255.0\n",
        "x_test = x_test.astype('float16') / 255.0\n",
        "\n",
        "\n",
        "# convert class vectors to binary class matrices\n",
        "y_train = tf.keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = tf.keras.utils.to_categorical(y_test, num_classes)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oPE5_vXPKFnA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_input_fn(batch_size=1000):\n",
        "  # convert the inputs to a Dataset.\n",
        "  dataset = tf.data.Dataset.from_tensor_slices((x_train,y_train))\n",
        "\n",
        "  # shuffle, repeat, and batch the examples.\n",
        "  dataset = dataset.shuffle(1000).repeat().batch(batch_size, drop_remainder=True)\n",
        "\n",
        "  # return the dataset.\n",
        "  return dataset"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xx_Ei88J8Aax",
        "colab_type": "text"
      },
      "source": [
        "## 3. Define Deep Learning  Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SIqomSCn8AwQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learning_rate = 0.001\n",
        "filter_sz = 3\n",
        "n_filters = 28\n",
        "\n",
        "def create_model():\n",
        "  Inp = tf.keras.Input(name='input', shape=input_shape, batch_size=None, dtype=tf.float32)\n",
        "\n",
        "  x = Conv2D(n_filters, kernel_size=(filter_sz, filter_sz), activation='relu', kernel_regularizer=regularizers.l2(l=0.0001), name = 'Conv_01')(Inp)\n",
        "  x = MaxPooling2D(pool_size=(2, 2),name = 'MaxPool_01')(x)\n",
        "  #  kernel_regularizer=regularizers.l2(l=0.00005)\n",
        "  x = Conv2D(2*n_filters, (filter_sz, filter_sz), activation='relu', name = 'Conv_02')(x)\n",
        "  x = MaxPooling2D(pool_size=(2, 2),name = 'MaxPool_02')(x)\n",
        "  x = Conv2D(2*n_filters, (filter_sz, filter_sz), activation='relu',  name = 'Conv_03')(x)\n",
        "  x = MaxPooling2D(pool_size=(2, 2),name = 'MaxPool_03')(x)\n",
        "  x = Conv2D(n_filters, (filter_sz, filter_sz), activation='relu',  name = 'Conv_04')(x)\n",
        "  x = MaxPooling2D(pool_size=(2, 2),name = 'MaxPool_04')(x)\n",
        "  x = Flatten(name = 'Flatten_01')(x)\n",
        "  x = Dense(2*n_filters, activation='relu',name = 'Dense_01')(x)\n",
        "  x = Dense(num_classes, activation='relu',name = 'Dense_02')(x)\n",
        "  x = Dropout(0.5,name = 'Dropout_02')(x)\n",
        "  output = Dense(num_classes, activation='softmax',name = 'Dense_out')(x)\n",
        "  \n",
        "  return tf.keras.models.Model(inputs=[Inp], outputs=[output])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ykyYZP-xBeT0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tpu_grpc_url = \"grpc://\"+os.environ[\"COLAB_TPU_ADDR\"]\n",
        "cluster_resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu=tpu_grpc_url)\n",
        "tf.config.experimental_connect_to_host(cluster_resolver.master())\n",
        "tf.tpu.experimental.initialize_tpu_system(cluster_resolver)\n",
        "tpu_strategy = tf.distribute.experimental.TPUStrategy(cluster_resolver)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PgrD7aaf8JRW",
        "colab_type": "text"
      },
      "source": [
        "## 4. Train The Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a5mrxXuz8KHK",
        "colab_type": "code",
        "outputId": "f4ff7ee2-2ce5-48ca-bf85-cd0975e7b758",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 5749
        }
      },
      "source": [
        "with tpu_strategy.scope():\n",
        "  model = create_model()\n",
        "  opt = tf.train.AdamOptimizer(learning_rate)\n",
        "  #opt = tf.train.AdadeltaOptimizer()\n",
        "  model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['acc'])\n",
        "  model.summary()\n",
        "  model.fit(x_train, y_train,\n",
        "          batch_size=batch_size,\n",
        "          epochs=epochs,\n",
        "          verbose=1,\n",
        "          validation_data=(x_test, y_test))\n",
        "  score = model.evaluate(x_test, y_test, batch_size=batch_size, verbose=1)\n",
        "  print('\\n########################################\\n#   T E S T    A C C U R A C Y:', score[1]*100, \"%\\n########################################\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0621 14:46:20.968342 140397540263808 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input (InputLayer)           [(None, 56, 56, 3)]       0         \n",
            "_________________________________________________________________\n",
            "Conv_01 (Conv2D)             (None, 54, 54, 28)        784       \n",
            "_________________________________________________________________\n",
            "MaxPool_01 (MaxPooling2D)    (None, 27, 27, 28)        0         \n",
            "_________________________________________________________________\n",
            "Conv_02 (Conv2D)             (None, 25, 25, 56)        14168     \n",
            "_________________________________________________________________\n",
            "MaxPool_02 (MaxPooling2D)    (None, 12, 12, 56)        0         \n",
            "_________________________________________________________________\n",
            "Conv_03 (Conv2D)             (None, 10, 10, 56)        28280     \n",
            "_________________________________________________________________\n",
            "MaxPool_03 (MaxPooling2D)    (None, 5, 5, 56)          0         \n",
            "_________________________________________________________________\n",
            "Conv_04 (Conv2D)             (None, 3, 3, 28)          14140     \n",
            "_________________________________________________________________\n",
            "MaxPool_04 (MaxPooling2D)    (None, 1, 1, 28)          0         \n",
            "_________________________________________________________________\n",
            "Flatten_01 (Flatten)         (None, 28)                0         \n",
            "_________________________________________________________________\n",
            "Dense_01 (Dense)             (None, 56)                1624      \n",
            "_________________________________________________________________\n",
            "Dense_02 (Dense)             (None, 10)                570       \n",
            "_________________________________________________________________\n",
            "Dropout_02 (Dropout)         (None, 10)                0         \n",
            "_________________________________________________________________\n",
            "Dense_out (Dense)            (None, 10)                110       \n",
            "=================================================================\n",
            "Total params: 59,676\n",
            "Trainable params: 59,676\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "W0621 14:46:25.319872 140397540263808 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/data/util/random_seed.py:58: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "W0621 14:46:30.871763 140397540263808 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training_distributed.py:411: Variable.load (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Prefer Variable.assign which has equivalent behavior in 2.X.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "1/1 [==============================] - 3s 3s/step\n",
            "1/1 [==============================] - 3s 3s/step\n",
            "4/4 [==============================] - 6s 1s/step - loss: 2.3030 - acc: 0.1028 - val_loss: 2.3024 - val_acc: 0.1240\n",
            "Epoch 2/100\n",
            "1/1 [==============================] - 3s 3s/step\n",
            "1/1 [==============================] - 3s 3s/step\n",
            "4/4 [==============================] - 5s 1s/step - loss: 2.3024 - acc: 0.1065 - val_loss: 2.3008 - val_acc: 0.1280\n",
            "Epoch 3/100\n",
            "1/1 [==============================] - 3s 3s/step\n",
            "1/1 [==============================] - 3s 3s/step\n",
            "4/4 [==============================] - 6s 2s/step - loss: 2.3004 - acc: 0.1258 - val_loss: 2.2990 - val_acc: 0.1410\n",
            "Epoch 4/100\n",
            "1/1 [==============================] - 4s 4s/step\n",
            "1/1 [==============================] - 4s 4s/step\n",
            "4/4 [==============================] - 7s 2s/step - loss: 2.2981 - acc: 0.1268 - val_loss: 2.2951 - val_acc: 0.1590\n",
            "Epoch 5/100\n",
            "1/1 [==============================] - 4s 4s/step\n",
            "1/1 [==============================] - 4s 4s/step\n",
            "4/4 [==============================] - 7s 2s/step - loss: 2.2946 - acc: 0.1268 - val_loss: 2.2895 - val_acc: 0.1410\n",
            "Epoch 6/100\n",
            "1/1 [==============================] - 5s 5s/step\n",
            "1/1 [==============================] - 5s 5s/step\n",
            "4/4 [==============================] - 8s 2s/step - loss: 2.2907 - acc: 0.1203 - val_loss: 2.2855 - val_acc: 0.1570\n",
            "Epoch 7/100\n",
            "1/1 [==============================] - 5s 5s/step\n",
            "1/1 [==============================] - 5s 5s/step\n",
            "4/4 [==============================] - 9s 2s/step - loss: 2.2890 - acc: 0.1348 - val_loss: 2.2800 - val_acc: 0.1580\n",
            "Epoch 8/100\n",
            "1/1 [==============================] - 5s 5s/step\n",
            "1/1 [==============================] - 5s 5s/step\n",
            "4/4 [==============================] - 9s 2s/step - loss: 2.2802 - acc: 0.1358 - val_loss: 2.2747 - val_acc: 0.1370\n",
            "Epoch 9/100\n",
            "1/1 [==============================] - 6s 6s/step\n",
            "1/1 [==============================] - 6s 6s/step\n",
            "4/4 [==============================] - 11s 3s/step - loss: 2.2783 - acc: 0.1380 - val_loss: 2.2678 - val_acc: 0.1900\n",
            "Epoch 10/100\n",
            "1/1 [==============================] - 6s 6s/step\n",
            "1/1 [==============================] - 6s 6s/step\n",
            "4/4 [==============================] - 11s 3s/step - loss: 2.2701 - acc: 0.1463 - val_loss: 2.2608 - val_acc: 0.1870\n",
            "Epoch 11/100\n",
            "1/1 [==============================] - 7s 7s/step\n",
            "1/1 [==============================] - 7s 7s/step\n",
            "4/4 [==============================] - 11s 3s/step - loss: 2.2661 - acc: 0.1493 - val_loss: 2.2546 - val_acc: 0.1790\n",
            "Epoch 12/100\n",
            "1/1 [==============================] - 7s 7s/step\n",
            "1/1 [==============================] - 7s 7s/step\n",
            "4/4 [==============================] - 12s 3s/step - loss: 2.2632 - acc: 0.1493 - val_loss: 2.2454 - val_acc: 0.1770\n",
            "Epoch 13/100\n",
            "1/1 [==============================] - 8s 8s/step\n",
            "1/1 [==============================] - 8s 8s/step\n",
            "4/4 [==============================] - 13s 3s/step - loss: 2.2588 - acc: 0.1380 - val_loss: 2.2378 - val_acc: 0.1980\n",
            "Epoch 14/100\n",
            "1/1 [==============================] - 8s 8s/step\n",
            "1/1 [==============================] - 8s 8s/step\n",
            "4/4 [==============================] - 13s 3s/step - loss: 2.2586 - acc: 0.1493 - val_loss: 2.2341 - val_acc: 0.1950\n",
            "Epoch 15/100\n",
            "1/1 [==============================] - 9s 9s/step\n",
            "1/1 [==============================] - 9s 9s/step\n",
            "4/4 [==============================] - 15s 4s/step - loss: 2.2435 - acc: 0.1475 - val_loss: 2.2297 - val_acc: 0.1950\n",
            "Epoch 16/100\n",
            "1/1 [==============================] - 9s 9s/step\n",
            "1/1 [==============================] - 9s 9s/step\n",
            "4/4 [==============================] - 16s 4s/step - loss: 2.2496 - acc: 0.1543 - val_loss: 2.2161 - val_acc: 0.2010\n",
            "Epoch 17/100\n",
            "1/1 [==============================] - 10s 10s/step\n",
            "1/1 [==============================] - 10s 10s/step\n",
            "4/4 [==============================] - 16s 4s/step - loss: 2.2377 - acc: 0.1525 - val_loss: 2.2157 - val_acc: 0.1790\n",
            "Epoch 18/100\n",
            "1/1 [==============================] - 11s 11s/step\n",
            "1/1 [==============================] - 11s 11s/step\n",
            "4/4 [==============================] - 17s 4s/step - loss: 2.2424 - acc: 0.1485 - val_loss: 2.2154 - val_acc: 0.2010\n",
            "Epoch 19/100\n",
            "1/1 [==============================] - 11s 11s/step\n",
            "1/1 [==============================] - 11s 11s/step\n",
            "4/4 [==============================] - 18s 5s/step - loss: 2.2308 - acc: 0.1478 - val_loss: 2.2051 - val_acc: 0.2150\n",
            "Epoch 20/100\n",
            "1/1 [==============================] - 11s 11s/step\n",
            "1/1 [==============================] - 11s 11s/step\n",
            "4/4 [==============================] - 18s 5s/step - loss: 2.2195 - acc: 0.1655 - val_loss: 2.1913 - val_acc: 0.2230\n",
            "Epoch 21/100\n",
            "1/1 [==============================] - 12s 12s/step\n",
            "1/1 [==============================] - 12s 12s/step\n",
            "4/4 [==============================] - 19s 5s/step - loss: 2.2228 - acc: 0.1593 - val_loss: 2.1889 - val_acc: 0.2140\n",
            "Epoch 22/100\n",
            "1/1 [==============================] - 13s 13s/step\n",
            "1/1 [==============================] - 13s 13s/step\n",
            "4/4 [==============================] - 21s 5s/step - loss: 2.2192 - acc: 0.1648 - val_loss: 2.1934 - val_acc: 0.1960\n",
            "Epoch 23/100\n",
            "1/1 [==============================] - 13s 13s/step\n",
            "1/1 [==============================] - 13s 13s/step\n",
            "4/4 [==============================] - 21s 5s/step - loss: 2.2092 - acc: 0.1630 - val_loss: 2.1934 - val_acc: 0.2030\n",
            "Epoch 24/100\n",
            "1/1 [==============================] - 13s 13s/step\n",
            "1/1 [==============================] - 13s 13s/step\n",
            "4/4 [==============================] - 23s 6s/step - loss: 2.2138 - acc: 0.1678 - val_loss: 2.1859 - val_acc: 0.2120\n",
            "Epoch 25/100\n",
            "1/1 [==============================] - 14s 14s/step\n",
            "1/1 [==============================] - 14s 14s/step\n",
            "4/4 [==============================] - 24s 6s/step - loss: 2.2161 - acc: 0.1635 - val_loss: 2.1784 - val_acc: 0.2120\n",
            "Epoch 26/100\n",
            "1/1 [==============================] - 15s 15s/step\n",
            "1/1 [==============================] - 15s 15s/step\n",
            "4/4 [==============================] - 24s 6s/step - loss: 2.2003 - acc: 0.1745 - val_loss: 2.1741 - val_acc: 0.2160\n",
            "Epoch 27/100\n",
            "1/1 [==============================] - 15s 15s/step\n",
            "1/1 [==============================] - 15s 15s/step\n",
            "4/4 [==============================] - 26s 7s/step - loss: 2.1915 - acc: 0.1763 - val_loss: 2.1662 - val_acc: 0.1940\n",
            "Epoch 28/100\n",
            "1/1 [==============================] - 17s 17s/step\n",
            "1/1 [==============================] - 17s 17s/step\n",
            "4/4 [==============================] - 28s 7s/step - loss: 2.1898 - acc: 0.1713 - val_loss: 2.1570 - val_acc: 0.2270\n",
            "Epoch 29/100\n",
            "1/1 [==============================] - 17s 17s/step\n",
            "1/1 [==============================] - 17s 17s/step\n",
            "4/4 [==============================] - 28s 7s/step - loss: 2.1805 - acc: 0.1820 - val_loss: 2.1467 - val_acc: 0.2320\n",
            "Epoch 30/100\n",
            "1/1 [==============================] - 18s 18s/step\n",
            "1/1 [==============================] - 18s 18s/step\n",
            "4/4 [==============================] - 30s 8s/step - loss: 2.1700 - acc: 0.1820 - val_loss: 2.1327 - val_acc: 0.2260\n",
            "Epoch 31/100\n",
            "1/1 [==============================] - 18s 18s/step\n",
            "1/1 [==============================] - 18s 18s/step\n",
            "4/4 [==============================] - 30s 7s/step - loss: 2.1581 - acc: 0.1883 - val_loss: 2.1316 - val_acc: 0.2350\n",
            "Epoch 32/100\n",
            "1/1 [==============================] - 19s 19s/step\n",
            "1/1 [==============================] - 19s 19s/step\n",
            "4/4 [==============================] - 33s 8s/step - loss: 2.1480 - acc: 0.1970 - val_loss: 2.1166 - val_acc: 0.2350\n",
            "Epoch 33/100\n",
            "1/1 [==============================] - 22s 22s/step\n",
            "1/1 [==============================] - 22s 22s/step\n",
            "4/4 [==============================] - 37s 9s/step - loss: 2.1466 - acc: 0.1983 - val_loss: 2.1140 - val_acc: 0.2390\n",
            "Epoch 34/100\n",
            "1/1 [==============================] - 21s 21s/step\n",
            "1/1 [==============================] - 21s 21s/step\n",
            "4/4 [==============================] - 35s 9s/step - loss: 2.1419 - acc: 0.2075 - val_loss: 2.0968 - val_acc: 0.2410\n",
            "Epoch 35/100\n",
            "1/1 [==============================] - 24s 24s/step\n",
            "1/1 [==============================] - 24s 24s/step\n",
            "4/4 [==============================] - 38s 10s/step - loss: 2.1239 - acc: 0.2093 - val_loss: 2.0948 - val_acc: 0.2550\n",
            "Epoch 36/100\n",
            "1/1 [==============================] - 25s 25s/step\n",
            "1/1 [==============================] - 25s 25s/step\n",
            "4/4 [==============================] - 40s 10s/step - loss: 2.1320 - acc: 0.2150 - val_loss: 2.0862 - val_acc: 0.2550\n",
            "Epoch 37/100\n",
            "1/1 [==============================] - 25s 25s/step\n",
            "1/1 [==============================] - 25s 25s/step\n",
            "4/4 [==============================] - 42s 11s/step - loss: 2.1344 - acc: 0.2040 - val_loss: 2.0890 - val_acc: 0.2290\n",
            "Epoch 38/100\n",
            "1/1 [==============================] - 26s 26s/step\n",
            "1/1 [==============================] - 26s 26s/step\n",
            "4/4 [==============================] - 43s 11s/step - loss: 2.1323 - acc: 0.2123 - val_loss: 2.0730 - val_acc: 0.2770\n",
            "Epoch 39/100\n",
            "1/1 [==============================] - 27s 27s/step\n",
            "1/1 [==============================] - 27s 27s/step\n",
            "4/4 [==============================] - 45s 11s/step - loss: 2.1276 - acc: 0.2110 - val_loss: 2.0784 - val_acc: 0.2660\n",
            "Epoch 40/100\n",
            "1/1 [==============================] - 29s 29s/step\n",
            "1/1 [==============================] - 29s 29s/step\n",
            "4/4 [==============================] - 47s 12s/step - loss: 2.1147 - acc: 0.2178 - val_loss: 2.0717 - val_acc: 0.2760\n",
            "Epoch 41/100\n",
            "1/1 [==============================] - 29s 29s/step\n",
            "1/1 [==============================] - 29s 29s/step\n",
            "4/4 [==============================] - 48s 12s/step - loss: 2.1168 - acc: 0.2218 - val_loss: 2.0578 - val_acc: 0.2780\n",
            "Epoch 42/100\n",
            "1/1 [==============================] - 31s 31s/step\n",
            "1/1 [==============================] - 31s 31s/step\n",
            "4/4 [==============================] - 51s 13s/step - loss: 2.1048 - acc: 0.2203 - val_loss: 2.0536 - val_acc: 0.2770\n",
            "Epoch 43/100\n",
            "1/1 [==============================] - 32s 32s/step\n",
            "1/1 [==============================] - 32s 32s/step\n",
            "4/4 [==============================] - 53s 13s/step - loss: 2.0988 - acc: 0.2168 - val_loss: 2.0441 - val_acc: 0.2880\n",
            "Epoch 44/100\n",
            "1/1 [==============================] - 33s 33s/step\n",
            "1/1 [==============================] - 33s 33s/step\n",
            "4/4 [==============================] - 55s 14s/step - loss: 2.0943 - acc: 0.2310 - val_loss: 2.0269 - val_acc: 0.2850\n",
            "Epoch 45/100\n",
            "1/1 [==============================] - 34s 34s/step\n",
            "1/1 [==============================] - 34s 34s/step\n",
            "4/4 [==============================] - 55s 14s/step - loss: 2.0827 - acc: 0.2273 - val_loss: 2.0315 - val_acc: 0.2660\n",
            "Epoch 46/100\n",
            "1/1 [==============================] - 35s 35s/step\n",
            "1/1 [==============================] - 35s 35s/step\n",
            "4/4 [==============================] - 57s 14s/step - loss: 2.0915 - acc: 0.2310 - val_loss: 2.0214 - val_acc: 0.3150\n",
            "Epoch 47/100\n",
            "1/1 [==============================] - 35s 35s/step\n",
            "1/1 [==============================] - 35s 35s/step\n",
            "4/4 [==============================] - 57s 14s/step - loss: 2.0838 - acc: 0.2265 - val_loss: 2.0428 - val_acc: 0.2970\n",
            "Epoch 48/100\n",
            "1/1 [==============================] - 40s 40s/step\n",
            "1/1 [==============================] - 40s 40s/step\n",
            "4/4 [==============================] - 65s 16s/step - loss: 2.0751 - acc: 0.2335 - val_loss: 2.0057 - val_acc: 0.2830\n",
            "Epoch 49/100\n",
            "1/1 [==============================] - 39s 39s/step\n",
            "1/1 [==============================] - 39s 39s/step\n",
            "4/4 [==============================] - 63s 16s/step - loss: 2.0750 - acc: 0.2243 - val_loss: 1.9981 - val_acc: 0.2990\n",
            "Epoch 50/100\n",
            "1/1 [==============================] - 40s 40s/step\n",
            "1/1 [==============================] - 40s 40s/step\n",
            "4/4 [==============================] - 65s 16s/step - loss: 2.0571 - acc: 0.2335 - val_loss: 2.0010 - val_acc: 0.3060\n",
            "Epoch 51/100\n",
            "1/1 [==============================] - 41s 41s/step\n",
            "1/1 [==============================] - 41s 41s/step\n",
            "4/4 [==============================] - 68s 17s/step - loss: 2.0429 - acc: 0.2380 - val_loss: 1.9774 - val_acc: 0.3140\n",
            "Epoch 52/100\n",
            "1/1 [==============================] - 41s 41s/step\n",
            "1/1 [==============================] - 41s 41s/step\n",
            "4/4 [==============================] - 67s 17s/step - loss: 2.0537 - acc: 0.2380 - val_loss: 1.9804 - val_acc: 0.3010\n",
            "Epoch 53/100\n",
            "1/1 [==============================] - 45s 45s/step\n",
            "1/1 [==============================] - 45s 45s/step\n",
            "4/4 [==============================] - 74s 18s/step - loss: 2.0344 - acc: 0.2440 - val_loss: 1.9650 - val_acc: 0.3370\n",
            "Epoch 54/100\n",
            "1/1 [==============================] - 44s 44s/step\n",
            "1/1 [==============================] - 44s 44s/step\n",
            "4/4 [==============================] - 73s 18s/step - loss: 2.0206 - acc: 0.2508 - val_loss: 1.9491 - val_acc: 0.3230\n",
            "Epoch 55/100\n",
            "1/1 [==============================] - 47s 47s/step\n",
            "1/1 [==============================] - 47s 47s/step\n",
            "4/4 [==============================] - 77s 19s/step - loss: 2.0136 - acc: 0.2528 - val_loss: 1.9527 - val_acc: 0.3260\n",
            "Epoch 56/100\n",
            "1/1 [==============================] - 48s 48s/step\n",
            "1/1 [==============================] - 48s 48s/step\n",
            "4/4 [==============================] - 80s 20s/step - loss: 2.0136 - acc: 0.2530 - val_loss: 1.9584 - val_acc: 0.3160\n",
            "Epoch 57/100\n",
            "1/1 [==============================] - 50s 50s/step\n",
            "1/1 [==============================] - 50s 50s/step\n",
            "4/4 [==============================] - 80s 20s/step - loss: 2.0170 - acc: 0.2463 - val_loss: 1.9478 - val_acc: 0.3180\n",
            "Epoch 58/100\n",
            "1/1 [==============================] - 50s 50s/step\n",
            "1/1 [==============================] - 50s 50s/step\n",
            "4/4 [==============================] - 83s 21s/step - loss: 2.0238 - acc: 0.2385 - val_loss: 1.9485 - val_acc: 0.3180\n",
            "Epoch 59/100\n",
            "1/1 [==============================] - 51s 51s/step\n",
            "1/1 [==============================] - 51s 51s/step\n",
            "4/4 [==============================] - 85s 21s/step - loss: 1.9973 - acc: 0.2645 - val_loss: 1.9335 - val_acc: 0.3250\n",
            "Epoch 60/100\n",
            "1/1 [==============================] - 54s 54s/step\n",
            "1/1 [==============================] - 54s 54s/step\n",
            "4/4 [==============================] - 88s 22s/step - loss: 2.0077 - acc: 0.2493 - val_loss: 1.9143 - val_acc: 0.3470\n",
            "Epoch 61/100\n",
            "1/1 [==============================] - 52s 52s/step\n",
            "1/1 [==============================] - 52s 52s/step\n",
            "4/4 [==============================] - 85s 21s/step - loss: 2.0114 - acc: 0.2533 - val_loss: 1.9366 - val_acc: 0.3550\n",
            "Epoch 62/100\n",
            "1/1 [==============================] - 56s 56s/step\n",
            "1/1 [==============================] - 56s 56s/step\n",
            "4/4 [==============================] - 93s 23s/step - loss: 1.9928 - acc: 0.2643 - val_loss: 1.9368 - val_acc: 0.3390\n",
            "Epoch 63/100\n",
            "1/1 [==============================] - 57s 57s/step\n",
            "1/1 [==============================] - 57s 57s/step\n",
            "4/4 [==============================] - 91s 23s/step - loss: 1.9832 - acc: 0.2673 - val_loss: 1.9216 - val_acc: 0.3260\n",
            "Epoch 64/100\n",
            "1/1 [==============================] - 57s 57s/step\n",
            "1/1 [==============================] - 57s 57s/step\n",
            "4/4 [==============================] - 92s 23s/step - loss: 1.9762 - acc: 0.2718 - val_loss: 1.9225 - val_acc: 0.3380\n",
            "Epoch 65/100\n",
            "1/1 [==============================] - 59s 59s/step\n",
            "1/1 [==============================] - 59s 59s/step\n",
            "4/4 [==============================] - 95s 24s/step - loss: 1.9832 - acc: 0.2673 - val_loss: 1.9092 - val_acc: 0.3540\n",
            "Epoch 66/100\n",
            "1/1 [==============================] - 62s 62s/step\n",
            "1/1 [==============================] - 62s 62s/step\n",
            "4/4 [==============================] - 102s 25s/step - loss: 1.9665 - acc: 0.2683 - val_loss: 1.8921 - val_acc: 0.3540\n",
            "Epoch 67/100\n",
            "1/1 [==============================] - 63s 63s/step\n",
            "1/1 [==============================] - 63s 63s/step\n",
            "4/4 [==============================] - 104s 26s/step - loss: 1.9624 - acc: 0.2653 - val_loss: 1.8922 - val_acc: 0.3410\n",
            "Epoch 68/100\n",
            "1/1 [==============================] - 63s 63s/step\n",
            "1/1 [==============================] - 63s 63s/step\n",
            "4/4 [==============================] - 103s 26s/step - loss: 1.9740 - acc: 0.2730 - val_loss: 1.9036 - val_acc: 0.3470\n",
            "Epoch 69/100\n",
            "1/1 [==============================] - 67s 67s/step\n",
            "1/1 [==============================] - 67s 67s/step\n",
            "4/4 [==============================] - 110s 27s/step - loss: 1.9609 - acc: 0.2910 - val_loss: 1.8951 - val_acc: 0.3510\n",
            "Epoch 70/100\n",
            "1/1 [==============================] - 69s 69s/step\n",
            "1/1 [==============================] - 69s 69s/step\n",
            "4/4 [==============================] - 114s 29s/step - loss: 1.9435 - acc: 0.2770 - val_loss: 1.8674 - val_acc: 0.3600\n",
            "Epoch 71/100\n",
            "1/1 [==============================] - 64s 64s/step\n",
            "1/1 [==============================] - 64s 64s/step\n",
            "4/4 [==============================] - 106s 27s/step - loss: 1.9550 - acc: 0.2728 - val_loss: 1.8895 - val_acc: 0.3520\n",
            "Epoch 72/100\n",
            "1/1 [==============================] - 68s 68s/step\n",
            "1/1 [==============================] - 68s 68s/step\n",
            "4/4 [==============================] - 114s 28s/step - loss: 1.9550 - acc: 0.2745 - val_loss: 1.8940 - val_acc: 0.3540\n",
            "Epoch 73/100\n",
            "1/1 [==============================] - 70s 70s/step\n",
            "1/1 [==============================] - 70s 70s/step\n",
            "4/4 [==============================] - 117s 29s/step - loss: 1.9393 - acc: 0.2815 - val_loss: 1.8688 - val_acc: 0.3620\n",
            "Epoch 74/100\n",
            "3/4 [=====================>........] - ETA: 0s - loss: 1.9335 - acc: 0.2913"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G24qsjad81zS",
        "colab_type": "text"
      },
      "source": [
        "## 5. Display !"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "en_XPFLi94W6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from matplotlib import pyplot as plt\n",
        "import random\n",
        "\n",
        "labels_dict = food_mnist.labels()\n",
        "img_class = model.predict(x_test, batch_size=batch_size)\n",
        "\n",
        "for x in range(5):\n",
        "  idx = random.randint(0,x_test.shape[0])\n",
        "  img = x_test[idx]\n",
        "  fig=plt.figure(figsize=(3,3), dpi=72, facecolor='w', edgecolor='k')\n",
        "  plt.axis('off')\n",
        "  plt.imshow(img)\n",
        "  plt.title(\"food test \" + str(idx) + \": \" + labels_dict[np.argmax(img_class[idx])] + \n",
        "            \" (\" + labels_dict[np.argmax(y_test[idx])] + \")\" )\n",
        "  \n",
        "  plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}